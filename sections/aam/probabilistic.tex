\subsection{Probabilistic Formulation}
\label{sec:probabilistic_aam}

A probabilistic interpretation of AAMs can be obtained by rewriting Equations \ref{eq:aam_1} and \ref{eq:aam_2} assuming probabilistic generative models for shape and appearance generation. In this paper, motivated by seminal works on Probabilistic Component Analysis (PPCA) and object tracking \cite{Tipping1999, Roweis1998, Moghaddam1997}, we will assume probabilistic models for shape and appearance generation with both Gaussian noise and Gaussian priors over the latent shape and appearance spaces\footnote{This formulation is generic and one could assume other probabilistic generative models \cite{vanderMaaten2010, Bach2005, Prince2012, Nicolau2014} to define novel probabilistic versions of AAMs.}:
\begin{equation}
	\begin{aligned}
		\mathbf{s} & = \bar{\mathbf{s}} + \mathbf{S} \mathbf{p} + \boldsymbol{\varepsilon}
		\\
		\mathbf{p} & \sim \mathcal{N} \left( \mathbf{0}, \mathbf{\Lambda} \right) 
		\\
		\boldsymbol{\varepsilon} & \sim \mathcal{N} \left( \mathbf{0}, \rho^2 \mathbf{I} \right) 
	\end{aligned}
	\label{eq:paam_1}
\end{equation}
\begin{equation}
	\begin{aligned}
		\mathbf{i}[\mathbf{p}] & = \bar{\mathbf{a}} + \mathbf{A} \mathbf{c} + \boldsymbol{\epsilon}
		\\
		\mathbf{c} & \sim \mathcal{N} \left( \mathbf{0}, \mathbf{\Sigma} \right) 
		\\
		\boldsymbol{\epsilon} & \sim \mathcal{N} \left( \mathbf{0}, \sigma^2 \mathbf{I} \right) 
	\end{aligned}
	\label{eq:paam_2}
\end{equation}
where the diagonal matrices $\mathbf{\Lambda} = \textrm{diag}(\lambda_{\mathbf{s}_1}, \cdots, \lambda_{\mathbf{s}_m})$ and $\mathbf{\Sigma} = \textrm{diag}(\lambda_{\mathbf{a}_1}, \cdots, \lambda_{\mathbf{a}_m})$ contain the eigenvalues associated to shape and appearance eigenvectors respectively and where $\rho^2$ and $\sigma^2$ denote the estimated shape and image noise\footnote{\label{foot:noise}Theoretically, the optimal value for $\rho^2$ and $\sigma^2$ is the average value of the eigenvalues associated to the discarded shape and appearance eigenvectors respectively i.e. \mbox{$\rho^{2} = \frac{1}{N-n}\sum_{i=n}^N \lambda_{\mathbf{s}_i}$} and \mbox{$\sigma^{2} = \frac{1}{M-m}\sum_{i=m}^M \lambda_{\mathbf{a}_i}$} \cite{Moghaddam1997}.} respectively.

This probabilistic formulation will be used to derive Maximum A Posteriori (MAP) and Bayesian cost functions for fitting AAMs presented in Sections \ref{sec:rssd} and \ref{sec:rpo}.

% This probabilistic formulation can be used to derive Maximum A Posteriori (MAP) version of all the existent AAMs fitting algorithms reviewed in this paper and it is an essential part of the derivation of the Bayesian inference algorithms for fitting AAMs \cite{Alabort2014} described in in Section \cite{sec:bayes}.