\subsection{Image Representation}
\label{sec:appearance}

AAMs have been often criticized due to their inability to generalize well under novel/unseen appearance variations. In fact, some authors \cite{Gross2005, vanderMaaten2010} argued that a low rank gaussian distribuition (as defined by a single linear model of appearance) in the intensity domain is unlikely to have sufficient modeling power to accurately capture the structure of the complex non-linear manifolds defining the appearance of most objects.

However, recent works \cite{Tzimiropoulos2013, Alabort2014, Tzimiropoulos2014, Kossaifi2014} have shown that the previous is not necessary true if the linear appearance model is learned from a rich distribution of training samples. In particular, Tzimiropoulos and Pantic \cite{Tzimiropoulos2013} showed that, for the specific case of faces, a single linear model of appearance  in the intensity domain can effectively reconstruct novel/unseen images with similar characteristics to those from which the model was learned from. 

On the other hand, a number of authors \cite{Cootes2001b,Kittipanya2006,Langs2006,Zhou2010,Lucey2013,Tzimiropoulos2012,Tzimiropoulos2014,Antonakos2014} have shown that the use of richer and more descriptive image representations can greatly improve the generalization capabilities of AAMs. The basic idea behind the majority of these works consists of creating multi-channel image representations of the original single-channel intensity images by computing \emph{dense} feature descriptors at each pixel. A linear model of appearance can be directly learned on this new multi-channel representation. Antonakos et al. \cite{Antonakos2014} have recently shown that, by using highly engineered feature descriptors such as Dense Scale Invariant Feature Transform (DSIFT) \cite{Lowe1999,Ce2011} or a dense version of Histograms of Oriented Gradients (HOG) \cite{Dalal2005}, this approach leads to state-of-the-art results in the problem of face alignment in-the-wild. Note that, as noted in their paper, this increase in generalitzation comes with a significant increases in computational cost.

In this paper, we present a complete evaluation of AAMs with respect to different fitting strategies rather than different appearance representations and, consequetly, we will limit the number of different appearance representations used to only two: (i) raw intensity and (ii) DSIFT. 

For a detailed review and performance evaluation of the latest image representations used in AAMs the interested reader is referred to \cite{Antonakos2014}.