\section{Optimization Methods}
\label{sec:opt}

The fitting strategies reviewed in section \ref{} have been derived using a first order Taylor expansion of either $\mathbf{i}[\mathbf{p} \circ \delta \mathbf{p}]$ (forward composition) or $\mathbf{t}[\delta \mathbf{p}] = \mathbf{m}[\delta \mathbf{p}] + \sum_{i=1}^m \mathbf{c}_i \mathbf{u}_i[\delta \mathbf{p}]$ (inverse composition). Consequently, all fitting strategies make use of the Gauss-Newton algorithm for obtaining optimal solution for the shape parameters increments $\delta \mathbf{p}$ at each iteration.

It is important to note that the previous are not the only two linearizations that can be performed in order to find the optimal shape parameters $\mathbf{p}$ in equation \ref{eq:ssd}. 

\subsection{Newton}

One can use the Newton method to solve \ref{eq:ssd} by performing a second order Taylor expansion of 

A Newton version of the Fast-SIC algorithm was originally proposed in \cite{}, following the structure of section \ref{sec:} in this section we derive a more general Newton update that can be easily adapted to derive Newton version of all the other algorithms presented by introducing the appropriate norms.  

\begin{equation}
	\begin{aligned}
		\mathbf{g}[\delta \mathbf{p}] & \approx  \mathbf{g} + \frac{\partial \mathbf{g}}{\partial \mathbf{p}} \delta \mathbf{p} + 
		\frac{1}{2}\delta \mathbf{p}^T \frac{\partial^2 \mathbf{g}}{\partial^2 \mathbf{p}} \delta \mathbf{p} 
		\\
		& \approx \frac{1}{2} \left\| \mathbf{i}[\mathbf{p}] - \mathbf{t} \right\|_{\mathbf{Q}}^2 + 
		\left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)^T \mathbf{Q} \mathbf{J} \delta \mathbf{p} + 
	\delta \mathbf{p}^T \mathbf{H} \delta \mathbf{p}
	\end{aligned}
\end{equation}

where that $|| \cdot ||_{\mathbf{Q}}$ denotes a arbitrary algorithm dependent vector norm where $\mathbf{Q}$ is its particular projection operator.

The jacobian $\mathbf{J}$ in equation \ref{} denotes the \emph{forward} or \emph{inverse} jacobian in equations \ref{eq:} and \ref{eq:} respectively depending on whether the incremental warp has been introduced on the image or model side.

On the other hand, the \emph{Newton} hessian $\mathbf{H}$ is defined for the forward case as

\begin{equation}
	\begin{aligned}
		\mathbf{H} = \left( \frac{\partial \mathcal{W}}{\partial \mathbf{p}}^T \nabla^2 \mathbf{i}[\mathbf{p}] \frac{\partial \mathcal{W}}{\partial \mathbf{p}} + 
		\nabla \mathbf{i}[\mathbf{p}] \frac{\partial^2 \mathcal{W}}{\partial^2 \mathbf{p}} \right)
		\mathbf{Q} \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)
	\end{aligned}
\end{equation}

and similarly for the inverse case

\begin{equation}
	\begin{aligned}
		\mathbf{H} = \left( \frac{\partial \mathcal{W}}{\partial \mathbf{p}}^T \nabla^2 \mathbf{t}[\mathbf{p}] \frac{\partial \mathcal{W}}{\partial \mathbf{p}} + 
		\nabla \mathbf{t}[\mathbf{p}] \frac{\partial^2 \mathcal{W}}{\partial^2 \mathbf{p}} \right)
		\mathbf{Q} \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)
	\end{aligned}
\end{equation}

Differentiating equation \ref{} and equating it to $\mathbf{0}$ the solution for $\delta \mathbf{p}$ is given by

\begin{equation}
	\begin{aligned}
		 \mathbf{0} & = \left( \mathbf{Q} \mathbf{J} \right)^T \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right) + \mathbf{H} \delta \mathbf{p}
		\\
		\delta \mathbf{p} & = \mathbf{H}^{-1} \left( \mathbf{Q} \mathbf{J} \right)^T \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)
	\end{aligned}
\end{equation}

\subsection{Steepest Descent}

In \cite{} Amberg et al. derived a Steepest Descent version of the Fast-SFC algorithm by directly using the gradient of $\mathbf{g}[\delta \mathbf{p}]$ to compute the increment on the shape parameters, 

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p} = - \kappa \mathbf{J}^T \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)
	\end{aligned}
\end{equation}

\subsection{Efficient Second Order Method}

In the field of image alignedment an algorithm

In this section we show how this second order optimization method can be used to solve equation \ref{eq:} and consequently used to derive ESM versions of the all the algorithms reviewed in section \ref{sec:}.

In order to derive ESM let us start by defining the second order Taylor expansion of $\mathbf{f}[\delta \mathbf{p}]$ using the forward compositional framework

\begin{equation}
	\begin{aligned}
		\mathbf{f}[\delta \mathbf{p}] \approx \mathbf{i}[\mathbf{p}] - \mathbf{t} + 
		\mathbf{J}_{\mathbf{i}} \delta \mathbf{p} + 
		\frac{1}{2} \delta \mathbf{p}^T \mathbf{H}_{\mathbf{i}} \delta \mathbf{p} + 
		O(\delta \mathbf{p}^3)
	\end{aligned}
\end{equation}

Now, under the necessary assumption

\begin{equation}
	\begin{aligned}
		\mathbf{i}[\mathbf{p}_o] = \mathbf{t} = \mathbf{m} + \mathbf{U} \mathbf{c}_o
	\end{aligned}
\end{equation}

it follows that for a small increment on the shape parameters $\delta \mathbf{p}$

\begin{equation}
	\begin{aligned}
		\mathbf{J}_\mathbf{t} & \approx \mathbf{J}_\mathbf{i} + \mathbf{H}_\mathbf{i} \delta \mathbf{p}
		\\
		\mathbf{H}_\mathbf{i} \delta \mathbf{p} & \approx \mathbf{J}_\mathbf{t} - \mathbf{J}_\mathbf{i} 
	\end{aligned}
\end{equation}

Substituting equation \ref{eq:} into equation \ref{eq:} leads to following expression

\begin{equation}
	\begin{aligned}
		\mathbf{f}[\delta \mathbf{p}] & \approx \mathbf{i}[\mathbf{p}] - \mathbf{t} + 
		\mathbf{J}_{\mathbf{i}} \delta \mathbf{p} + 
		\frac{1}{2} \left( \mathbf{J}_\mathbf{t} - \mathbf{J}_\mathbf{i} \right) \delta \mathbf{p}+
		O(\delta \mathbf{p}^3)
		\\
		& \approx \mathbf{i}[\mathbf{p}] - \mathbf{t} + 
		\frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{t} \right) \delta \mathbf{p}+
		O(\delta \mathbf{p}^3)
	\end{aligned}
\end{equation}

Note that the approximation in equation \ref{eq:} can be equivalently derived using the inverse compositional framework.

Substituting the previous approximation into equation \ref{eq:} we have that ESM defines the following optimization problem

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}} 
		|| \mathbf{i}[\mathbf{p}] - \mathbf{t} + \frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{t} \right) \delta \mathbf{p} ||^2
	\end{aligned}
\end{equation}

Defining the \emph{ESM} jacobian as $\mathbf{J}_{ESM} = \frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{t} \right)$ the solution for $\delta \mathbf{p}$ is given by

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p} = \left( \mathbf{J}^T_{ESM} \mathbf{J}_{ESM} \right)^{-1} \mathbf{J}^T_{ESM} \left( \mathbf{i}[\mathbf{p}] - \mathbf{t} \right)
	\end{aligned}
\end{equation}


\section{Asymmetric and Bidirectional Compositions}

The previous ESM algorithm can be alternatively derived by introducing an alternative compositional framework to the common forward and inverse compositional. Instead of introducing the incremental warp either on the image side or on the model side, this alternative framework, known as Bidirectional composition introduces incremental warps both on the image and model sides simultaneously. Consequently, both the image and the model jacobians are used to recover  

\paragraph{Dependent Composition}

Within the proposed framework, dependent composition is defined by following optimization problem

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p} \circ \alpha \delta \mathbf{p}] - \mathbf{t}_{\mathbf{c}_o}[(1-\alpha) \delta \mathbf{p}^{-1}] \right\|^2
	\end{aligned}
\end{equation}

The key assumption here is that the incremental warp introduced on the model side is the inverse of the one introduced on the image side, consequently both warps are controlled by the same set of shape parameters increments.

Using the first order approximation to the warp inversion described in \cite{}

\begin{equation}
	\begin{aligned}
		\mathcal{W}(\mathbf{x}; \mathbf{p})^{-1} \approx \mathcal{W}(\mathbf{x}; -\mathbf{p})
	\end{aligned}
\end{equation}

and the previous optimization problem simplifies to

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p} \circ \alpha \delta \mathbf{p}] - \mathbf{t}_{\mathbf{c}_o}[(\alpha - 1) \delta \mathbf{p}] \right\|^2
	\end{aligned}
\end{equation}

Similar to the forward and inverse compositional frameworks the solution for $\delta \mathbf{p}$ can be obtained by performing a first order Taylor expansion of the residual around $\delta \mathbf{p} = \mathbf{0}$

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o & = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p}] - \mathbf{t}_{\mathbf{c}_o} + \alpha \mathbf{J}_{forward} \delta \mathbf{p} + (\alpha - 1) \mathbf{J}_{inverse} \delta \mathbf{p} \right\|^2
		\\
		& = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p}] - \mathbf{t}_{\mathbf{c}_o} + \mathbf{J} \delta \mathbf{p} \right\|^2
	\end{aligned}
\end{equation}

where the \emph{dependent} jacobian $\mathbf{J}$ is defined as

\begin{equation}
	\begin{aligned}
		\mathbf{J} & = \alpha \mathbf{J}_{\mathbf{i}} + (\alpha - 1) \mathbf{J}_{\mathbf{t}_{\mathbf{c}_o}}
		\\
		& = \alpha \nabla \mathbf{i}[\mathbf{p}] \frac{\partial \mathcal{W}}{\partial \mathbf{p}} + 
		(\alpha - 1) \nabla \mathbf{t}_{\mathbf{c}_o} \frac{\partial \mathcal{W}}{\partial \mathbf{p}}
		\\
		& = \left( \alpha \nabla \mathbf{i}[\mathbf{p}] + (\alpha - 1) \nabla \mathbf{t}_{\mathbf{c}_o} \right) \frac{\partial \mathcal{W}}{\partial \mathbf{p}}
	\end{aligned}
\end{equation}

The solution for $\delta \mathbf{p}$ is given by:

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p} = \left( \mathbf{J}^T \mathbf{J} \right)^{-1} \mathbf{J}^T \left( \mathbf{i}[\mathbf{p}] - \mathbf{t}_{\mathbf{c}_o} \right)
	\end{aligned}
\end{equation}

Finally the update on the current image warp is obtained using the following update rule

\begin{equation}
	\begin{aligned}
		\mathbf{p} \leftarrow \mathbf{p} \circ \alpha \delta \mathbf{p} \circ (\alpha -1) \delta \mathbf{p}^{-1} 
	\end{aligned}
\end{equation}

The special case in which $\alpha = 0.5$ is also referred in the literature as Symmetric composition.

\paragraph{Bidirectional Composition}

The bidirectional compositional the  incremental  warps  introduced  on  the  image and model sides are assumed to be completely independent from each other and controlled by two different sets of shape parameters increments $\delta \mathbf{p}_{\mathbf{i}}$ and $\delta \mathbf{p}_{\mathbf{t}}$. It defines the following optimization problem

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p} \circ \delta \mathbf{p}_{\mathbf{i}}] - \mathbf{t}[\delta \mathbf{p}_{\mathbf{t}}^{-1}] \right\|^2
	\end{aligned}
\end{equation}

The first order Taylor expansion of the previous function is

\begin{equation}
	\begin{aligned}
		\delta \mathbf{p}_o & = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p}] - \mathbf{t}_{\mathbf{c}_o} + 
		\mathbf{J}_{\mathbf{i}} \delta \mathbf{p}_{\mathbf{i}} + \mathbf{J}_{\mathbf{t}} \delta \mathbf{p}_{\mathbf{t}} \right\|^2
		\\
		& = \underset{\delta \mathbf{p}}{\mathrm{arg\,min\;}}
		\left\| \mathbf{i}[\mathbf{p}] - \mathbf{t}_{\mathbf{c}_o} + \mathbf{J} 
		\begin{pmatrix}
		\delta \mathbf{p}_{\mathbf{i}}
		\\ 
		\delta \mathbf{p}_{\mathbf{t}}
		\end{pmatrix} \right\|^2
	\end{aligned}
\end{equation}

where the \emph{bidirectional} jacobian is defined as the concatenation of the forward and inverse jacobians

\begin{equation}
	\begin{aligned}
		\mathbf{J} = \left( \mathbf{J}_{\mathbf{i}}, \mathbf{J}_{\mathbf{t}} \right)
	\end{aligned}
\end{equation}

The solution for $\delta \mathbf{p}$ is again given by equation \ref{eq:}, and the update is computed using the following rule
\begin{equation}
	\begin{aligned}
		\mathbf{p} \leftarrow \mathbf{p} \circ \delta \mathbf{p}_{\mathbf{i}} \circ \delta \mathbf{p}_{\mathbf{t}}^{-1} 
	\end{aligned}
\end{equation}
