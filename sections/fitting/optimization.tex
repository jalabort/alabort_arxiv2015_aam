\subsection{Optimization Method}
\label{sec:optimization}

Step \ref{it:step_2} and \ref{it:step_3} in CGD algorithms, i.e. linearizing the cost and solving for the incremental warp respectively, depend on the specific optimization method used by the algorithm. In this paper, we distinguish between three main optimization methods\footnote{Amberg et al. proposed the use of the \emph{Steepest Descent} method \cite{Boyd2004} in \cite{Amberg2009}. However, their approach requires a special formulation of the motion model and it performs poorly using the standard independent AAM formulation \cite{Matthews2004} used in this work.}:
\begin{inparaenum}[\itshape i\upshape)]
    \item \emph{Gauss-Newton} \cite{Boyd2004, Matthews2004, Gross2005, Martins2010, Papandreou2008, Tzimiropoulos2013};
    \item \emph{Newton} \cite{Boyd2004, Kossaifi2014}; and
    \item \emph{Wiberg} \cite{Okatani2006, Strelow2012, Papandreou2008, Tzimiropoulos2013}.
\end{inparaenum}

The previous methods can be used to iteratively solve the non-linear optimization problems defined by Equations \ref{eq:prob_rssd} and \ref{eq:prob_po}. The main differences between them are:
\begin{enumerate}
    \item The term being linearized. Gauss-Newton and Wiberg linearize the residual $\mathbf{r}$ while Newton linearizes the whole data term $\mathcal{D}$.

    \item The way in which each method solves for the incremental parameters $\Delta \mathbf{c}$, $\Delta \mathbf{p}$ and $\Delta \mathbf{q}$. Gauss-Newton and Newton can either solve for them \emph{simultaneously} or in an \emph{alternated} fashion while Wiberg defines its own procedure to solve for different sets of parameters\footnote{Wiberg reduces to Gauss-Newton when only a single set of parameters needs to be inferred.}.
\end{enumerate}

The following subsections thoroughly explain how the previous optimization methods are used in CGD algorithms. In order to simplify their comprehension full derivations will be given for all methods using the SSD data term (Equation \ref{eq:ssd}) with both asymmetric (Section \ref{sec:asymmetric}) and bidirectional (Section \ref{sec:bidirectional}) compositions\footnote{These represent the most general cases because the derivations for forward, inverse and symmetric compositions can be directly obtained from the asymmetric one and they require solving for all sets of parameters.} while only direct solutions will be given for the project-out data term (Equation \ref{eq:po}).


\subsubsection{Gauss-Newton}
\label{sec:gauss_newton}

When \emph{asymmetric} composition is used, the optimization problem define by the SSD data term is:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{c}^*, \Delta \mathbf{p}^* & = \underset{\Delta \mathbf{c}, \Delta \mathbf{p}}{\mathrm{arg\,min\;}} \frac{1}{2} \mathbf{r}_a^T\mathbf{r}_a
    \label{eq:asymmetric_ssd}
    \end{aligned}
\end{equation}
where the asymmetric residual $\mathbf{r}_a$ is defined as:
\begin{equation}
    \begin{aligned}
		\mathbf{r}_a & = \mathbf{i}[\mathbf{p}_{k-1}^* \circ \alpha \Delta \mathbf{p}] -
		\\
		& \quad \, \, (\mathbf{a} + \mathbf{A}(\mathbf{c}^*_{k-1} + \Delta\mathbf{c})) [\beta \Delta \mathbf{p}^{-1}]
    \label{eq:asymmetric_residual}
    \end{aligned}
\end{equation}
The Gauss-Newton method solves the previous optimization problem by first performing a first order Taylor expansion of the residual around the incremental warps:
\begin{equation}
    \begin{aligned}
		\mathbf{r}_a(\Delta \boldsymbol{\ell}) & \approx \hat{\mathbf{r}}_a(\Delta \boldsymbol{\ell})
		\\
		& \approx \mathbf{r}_a + \frac{\partial \mathbf{r}_a}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell}
    \label{eq:asymmetric_residual_taylor}
    \end{aligned}
\end{equation}
and then solving the following approximation of the original problem:
\begin{equation}
    \begin{aligned}
        \Delta \boldsymbol{\ell}^* & = \underset{\Delta \boldsymbol{\ell}}{\mathrm{arg\,min\;}} \frac{1}{2} \hat{\mathbf{r}}_a^T\hat{\mathbf{r}}_a
    \label{eq:asymmetric_ssd_taylor}
    \end{aligned}
\end{equation}
where, in order to unclutter the notation, we have defined $\Delta \boldsymbol{\ell} = (\Delta \mathbf{c}^T, \Delta \mathbf{p}^T)^T$ and the partial derivative of the residual with respect to the previous parameters, i.e. the \emph{Jacobian} of the residual, is defined as:
\begin{equation}
    \begin{aligned}
		\frac{\partial \mathbf{r}_a}{\partial \Delta \boldsymbol{\ell}}& = \left( \frac{\partial \mathbf{r}_a}{\partial \Delta \mathbf{c}}, \frac{\partial \mathbf{r}_a}{\partial \Delta \mathbf{p}} \right)
		\\
		& = \left( -\mathbf{A}, \nabla \mathbf{t} \frac{\partial \mathcal{W}}{\partial \Delta \mathbf{p}} \right)
		\\
		& = \left( -\mathbf{A}, \mathbf{J}_\mathbf{t} \right)
    \label{eq:asymmetric_jacobian}
    \end{aligned}
\end{equation}
where $\nabla\mathbf{t} = \left( \alpha \nabla \mathbf{i}[\mathbf{p}_{k-1}^*]  + \beta \nabla (\mathbf{a} + \mathbf{A}\mathbf{c}_{k-1}^*) \right)$.

When \emph{bidirectional} composition is used, the optimization problem is defined as:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{c}^*, \Delta \mathbf{p}^*, \Delta \mathbf{q}^*& = \underset{\Delta \mathbf{c}, \Delta \mathbf{p}, \Delta \mathbf{q}}{\mathrm{arg\,min\;}} \frac{1}{2} \mathbf{r}_b^T\mathbf{r}_b
    \label{eq:bidirectional_ssd}
    \end{aligned}
\end{equation}
where the bidirectional residual $\mathbf{r}_b$ reduces to:
\begin{equation}
    \begin{aligned}
		\mathbf{r}_b & = \mathbf{i}[\mathbf{p}_{k-1}^* \circ \Delta \mathbf{p}] - (\mathbf{a} + \mathbf{A}(\mathbf{c}^*_{k-1} + \Delta\mathbf{c})) [\Delta \mathbf{q}]
    \label{eq:bidirectional_residual}
    \end{aligned}
\end{equation}
The Gauss-Newton method proceeds in exactly the same manner as before i.e. performing a first order Taylor expansion:
\begin{equation}
    \begin{aligned}
		\mathbf{r}_b(\Delta \boldsymbol{\ell}) & \approx \hat{\mathbf{r}}_b(\Delta \boldsymbol{\ell})
		\\
		& \approx \mathbf{r}_b + \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell}
    \label{eq:idirectional_residual_taylor}
    \end{aligned}
\end{equation}
and solving the approximated problem:
\begin{equation}
    \begin{aligned}
        \Delta \boldsymbol{\ell}^* & = \underset{\Delta \boldsymbol{\ell}}{\mathrm{arg\,min\;}} \frac{1}{2} \hat{\mathbf{r}}_b^T\hat{\mathbf{r}}_b
    \label{eq:bidirectional_ssd_taylor}
    \end{aligned}
\end{equation}
where, in this case, $\Delta \boldsymbol{\ell} = (\Delta \mathbf{c}^T, \Delta \mathbf{p}^T, \Delta \mathbf{q}^T)^T$ and the Jacobian of the residual is defined as:
\begin{equation}
    \begin{aligned}
		\frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}}& = \left( \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{c}}, \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{p}}, \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{q}} \right)
		\\
		& = \left( -\mathbf{A}, \mathbf{J}_{\mathbf{i}}, -\mathbf{J}_{\mathbf{a}} \right)
    \label{eq:bidirectional_jacobian}
    \end{aligned}
\end{equation}
where $\mathbf{J}_\mathbf{i} = \nabla \mathbf{i}[\mathbf{p}_{k-1}] \frac{\partial \mathcal{W}}{\partial \Delta \mathbf{q}}$ and $\mathbf{J}_\mathbf{a} = \nabla (\mathbf{a} + \mathbf{A}\mathbf{c}_{k-1}^*) \frac{\partial \mathcal{W}}{\partial \Delta \mathbf{q}}.$


\subsubsection*{Simultaneous}
\label{sec:gauss_newton_simultaneous}

The optimization problem defined by Equations \ref{eq:asymmetric_ssd_taylor}  and \ref{eq:bidirectional_ssd_taylor} can be solve with respect to all parameters simultaneously by simply equating their derivative to $0$:
\begin{equation}
    \begin{aligned}
		0 & = \frac{\partial\frac{1}{2}\hat{\mathbf{r}}^T \hat{\mathbf{r}}}{\partial \Delta \boldsymbol{\ell}}
		\\
		& = \frac{\partial\frac{1}{2}(\mathbf{r} + \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell})^T(\mathbf{r} + \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell})}{\partial \Delta \boldsymbol{\ell}}
		\\
		& = \left( \mathbf{r} + \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell} \right) \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}}^T
    \label{eq:ssd_bc}
    \end{aligned}
\end{equation}
The solution is given by:
\begin{equation}
    \begin{aligned}
		\Delta \boldsymbol{\ell}^* & =  -\left( \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \right)^{-1} \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}}^T \mathbf{r}
    \label{eq:sim_solution}
    \end{aligned}
\end{equation}
where $\left( \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \right)$ is known as the Gauss-Newton approximation to the \emph{Hessian} matrix.

Directly inverting $\left( \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}}{\partial \Delta \boldsymbol{\ell}} \right)$ has complexity $O((n + m)^3)$ for asymmetric composition and $O((2n + m)^3)$ for bidirectional composition\footnote{\label{foot:complexity}$m$ and $n$ denote the number of shape and appearance parameters respectively while $F$ denotes the number of pixels on the reference frame.}. However, one can take advantage of the problem structure and derive an algorithm with smaller complexity by using the \emph{Schur complement}\footnote{
Applying the Schur complement to the following system of equations:
\begin{equation*}
    \begin{aligned}
        \mathbf{A} \mathbf{x} + \mathbf{B} \mathbf{y} = \mathbf{a}
        \\
        \mathbf{C} \mathbf{x} + \mathbf{D} \mathbf{y} = \mathbf{b}
    \label{eq:schur_system}
    \end{aligned}
\end{equation*}
the solution for $\mathbf{x}$ is given by:
\begin{equation*}
    \begin{aligned}
        (\mathbf{A} - \mathbf{B}\mathbf{D}^{-1}\mathbf{C}) \mathbf{x} = \mathbf{a} - \mathbf{B}\mathbf{D}^{-1}\mathbf{b}
    \label{eq:schur_system}
    \end{aligned}
\end{equation*}
and the solution for $\mathbf{y}$ is obtained by substituting the value of $\mathbf{x}$ into the original system.}
\cite{Boyd2004}.

For \emph{asymmetric} composition we have:
\begin{equation}
    \begin{aligned}
    	-\left( \frac{\partial \mathbf{r}_a}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}_a}{\partial \Delta \boldsymbol{\ell}} \right) \Delta \boldsymbol{\ell} & = \frac{\partial \mathbf{r}_a}{\partial \Delta \boldsymbol{\ell}}^T \mathbf{r}
    	\\
        \begin{pmatrix}
            -\underbrace{\mathbf{A}^T \mathbf{A}}_{\mathbf{I}} & \mathbf{A}^T \mathbf{J}_{\mathbf{t}}
            \\
            \mathbf{J}_a^T \mathbf{A} & -\mathbf{J}_{\mathbf{t}}^T \mathbf{J}_{\mathbf{t}}
        \end{pmatrix}
        \begin{pmatrix}
            \Delta\mathbf{c}
            \\
            \Delta\mathbf{p}
        \end{pmatrix}
        & =
        \begin{pmatrix}
            -\mathbf{A}^T
            \\
            \mathbf{J}_{\mathbf{t}}^T
        \end{pmatrix} \mathbf{r}_a
    \label{eq:asymmetric_structure}
    \end{aligned}
\end{equation}
Applying the Schur complement, the solution for $\Delta\mathbf{p}$ is given by:
\begin{equation}
    \begin{aligned}
        -(\mathbf{J}_{\mathbf{t}}^T\mathbf{J}_{\mathbf{t}} + \mathbf{J}_{\mathbf{t}}^T\mathbf{A}\mathbf{A}^T\mathbf{J}_{\mathbf{t}}^T) \Delta \mathbf{p} & = \mathbf{J}_{\mathbf{t}}^T\mathbf{r} - \mathbf{J}_{\mathbf{t}}^T\mathbf{A} \mathbf{A}^T \mathbf{r}_a
        \\
        -\mathbf{J}_{\mathbf{t}}^T(\mathbf{I} - \mathbf{A} \mathbf{A}^T)\mathbf{J}_{\mathbf{t}} \Delta \mathbf{p} & = \mathbf{J}_{\mathbf{t}}^T(\mathbf{I} - \mathbf{A} \mathbf{A}^T)\mathbf{r}_a
        \\
        -\mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \Delta \mathbf{p} & = \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{r}_a
        \\
        \Delta \mathbf{p} & = -\left( \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^{-1} \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{r}_a
    \label{eq:asymmetric_schur_solution1}
    \end{aligned}
\end{equation}
and plugging the solution for $\Delta\mathbf{p}$ into equation \ref{eq:asymmetric_structure} the optimal value for $\Delta\mathbf{c}$ is obtained by:
\begin{equation}
    \begin{aligned}
        -\Delta \mathbf{c} + \mathbf{A}^T\mathbf{J}_{\mathbf{t}}\Delta\mathbf{p}^* & = -\mathbf{A}^T \mathbf{r}_a
        \\
        \Delta \mathbf{c} & = \mathbf{A}^T \left( \mathbf{r}_a + \mathbf{J}_{\mathbf{t}} \Delta\mathbf{p}^* \right)
    \label{eq:asymmetric_schur_solution2}
    \end{aligned}
\end{equation}
Using the above procedure the complexity\footnoteref{foot:complexity} of solving each Gauss-Newton step reduced to:
\begin{equation}
    \begin{aligned}
        O(
        \underbrace{nmF}_{\mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}}
        +
        \underbrace{n^2F + n^3}_{\left( \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^{-1}}
        )
    \label{eq:complexity_schur_asymmetric}
    \end{aligned}
\end{equation}

Using \emph{bidirectional} composition, we can apply the Schur complement either one or two times in order to take advantage of the $3\times3$ block structure of the matrix $\left( \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}} \right)$:
\begin{equation}
    \begin{aligned}
    	-\left( \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}} \right) \Delta \boldsymbol{\ell} & = \frac{\partial \mathbf{r}_b}{\partial \Delta \boldsymbol{\ell}}^T \mathbf{r}_b
    	\\
        \left(\begin{array}{c|cc}
            -\underbrace{\mathbf{A}^T \mathbf{A}}_{\mathbf{I}} & \mathbf{A}^T \mathbf{J}_{\mathbf{i}} & -\mathbf{A}^T \mathbf{J}_{\mathbf{a}}
            \\ \hline
            \mathbf{J}_{\mathbf{i}}^T \mathbf{A} & -\mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{a}}
            \\
            -\mathbf{J}_{\mathbf{a}}^T \mathbf{A} & \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{i}} & -\mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{a}}
        \end{array} \right)
        \begin{pmatrix}
            \Delta\mathbf{c}
            \\ \hline
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix}
        & =
        \begin{pmatrix}
            -\mathbf{A}^T
            \\ \hline
            \mathbf{J}_{\mathbf{i}}^T
            \\
            -\mathbf{J}_{\mathbf{a}}^T
        \end{pmatrix} \mathbf{r}_b
    \label{eq:bidirectional_structure}
    \end{aligned}
\end{equation}
Applying the Schur complement once, the combined solution for $(\Delta\mathbf{p}^T, \Delta\mathbf{q}^T)^T$ is given by:
\begin{equation}
    \begin{aligned}
        \begin{pmatrix}
            -\mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
            \\
            \mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & -\mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
            \\
        \end{pmatrix}
        \begin{pmatrix}
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix} & =
        \begin{pmatrix}
            \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}
            \\
            -\mathbf{J}_{\mathbf{a}}^T\bar{\mathbf{A}}
        \end{pmatrix} \mathbf{r}_b
       \\
       \begin{pmatrix}
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix} & =
        \begin{pmatrix}
            -\mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
            \\
            \mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & -\mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
            \\
        \end{pmatrix}^{-1}
        \\
        & \quad \,
        \begin{pmatrix}
            \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}
            \\
            -\mathbf{J}_{\mathbf{a}}^T\bar{\mathbf{A}}
        \end{pmatrix} \mathbf{r}_b
    \label{eq:bidirectional_schur_solution1}
    \end{aligned}
\end{equation}
Note that the complexity of inverting this new approximation to the Hessian matrix is $O((2n)^3)$\footnote{This is an important reduction in complexity because usually $m >> n$ in CGD algorithms.}. Similar as before, plugging the solutions for $\Delta\mathbf{p}$ and $\Delta\mathbf{q}$ into Equation \ref{eq:bidirectional_structure} we can infer the optimal value for $\Delta\mathbf{c}$ using:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{c} & = \mathbf{A}^T \left( \mathbf{r}_b - \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
    \label{eq:bidirectional_schur_solution2}
    \end{aligned}
\end{equation}
The total complexity per iteration of the previous approach is:
\begin{equation}
    \begin{aligned}
        O(
        \underbrace{2nmF}_{
        \begin{pmatrix}
            \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}
            \\
            -\mathbf{J}_{\mathbf{a}}^T\bar{\mathbf{A}}
        \end{pmatrix}}
	    +
        \underbrace{(2n)^2F + (2n)^3}_{
        \begin{pmatrix}
            -\mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
            \\
            \mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} & -\mathbf{J}_{\mathbf{a}}^T \bar{\mathbf{A}}\mathbf{J}_{\mathbf{a}}
        \end{pmatrix}^{-1}}
	    )
    \label{eq:complexity_schur_bidirectional1}
    \end{aligned}
\end{equation}

The Schur complement can be re-applied to Equation \ref{eq:bidirectional_schur_solution1} to derive a solution for $\Delta\mathbf{q}$ that only requires inverting a Hessian approximation matrix of size $n \times n$:
\begin{equation}
    \begin{aligned}
        \left( \mathbf{J}_{\mathbf{a}}^T\mathbf{P}\mathbf{J}_{\mathbf{a}} \right) \Delta \mathbf{q} & = \mathbf{J}_{\mathbf{a}}^T\mathbf{P}\mathbf{r}_b
        \\
        \Delta \mathbf{q} & = \left( \mathbf{J}_{\mathbf{a}}^T\mathbf{P}\mathbf{J}_{\mathbf{a}} \right)^{-1} \mathbf{J}_{\mathbf{a}}^T\mathbf{P}\mathbf{r}_b
    \label{eq:bidirectional_schur_solution3}
    \end{aligned}
\end{equation}
where we have defined the projection matrix $\mathbf{P}$ as:
\begin{equation}
    \begin{aligned}
		\mathbf{P} &= \bar{\mathbf{A}} - \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} \right)^{-1} \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}
		\label{eq:bidirectional_schur_projection}
    \end{aligned}
\end{equation}
and the solutions for $\Delta\mathbf{q}$ and $\Delta\mathbf{c}$ can be obtained by plugging the solutions for $\Delta\mathbf{q}$ into Equation \ref{eq:bidirectional_schur_solution1} and the solutions for $\Delta\mathbf{q}$ and $\Delta\mathbf{p}$ into Equation \ref{eq:bidirectional_structure} respectively:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{p} & = -\left( \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} \right)^{-1} \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}} \left(\mathbf{r}_b - \mathbf{J}_{\mathbf{a}}\Delta \mathbf{q}^* \right)
        \\
        \Delta\mathbf{c} & = \mathbf{A}^T \left( \mathbf{r}_b - \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
    \label{eq:bidirectional_schur_solution4}
    \end{aligned}
\end{equation}
The total complexity per iteration of the previous approach reduces to:
\begin{equation}
    \begin{aligned}
        O(
        \underbrace{2nmF}_{
            \mathbf{J}_{\mathbf{a}}^T\mathbf{P}
            \, \& \,
            \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}}
        +
        \underbrace{2n^2F + 2n^3}_{
            \left( \mathbf{J}_{\mathbf{a}}^T\mathbf{P}\mathbf{J}_{\mathbf{a}} \right)^{-1}
            \, \& \,
            \left( \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{i}} \right)^{-1}}
        )
    \label{eq:complexity_schur_bidirectional2}
    \end{aligned}
\end{equation}
Note that because of their reduced complexity, the solutions in Equations \ref{eq:bidirectional_schur_solution3} and \ref{eq:bidirectional_schur_solution4} are preferred over the ones defined by Equations \ref{eq:bidirectional_schur_solution1} and \ref{eq:bidirectional_schur_solution2}.

Finally, the solutions using the project-out cost function are:
\begin{itemize}
	\item For \emph{asymmetric} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{p} & = -\left( \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^{-1} \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{r}
	    \label{eq:asymmetric_schur_po_solution}
	    \end{aligned}
	\end{equation}
	with complexity\footnote{\label{foot:ic}In practice, the solutions for the project-out cost function can be computed slightly faster because they do not need to explicitly solve for $\Delta\mathbf{c}$. This is specially important in the \emph{inverse} compositional case because expressions of the form $(\mathbf{J}^T\mathbf{U}\mathbf{J})^{-1}\mathbf{J}^T\mathbf{U}$ can be completely precomputed and the complexity at each iteration reduces to $O(nF)$.} given by Equation \ref{eq:complexity_schur_asymmetric}.

	\item For \emph{bidirectional} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{q} & = \left( \mathbf{J}_{\bar{\mathbf{a}}}^T\mathbf{P}\mathbf{J}_{\bar{\mathbf{a}}} \right)^{-1} \mathbf{J}_{\bar{\mathbf{a}}}^T\mathbf{P}\mathbf{r}
	        \\
	        \Delta \mathbf{p} & = -\left( \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} \right)^{-1} \mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}} \left( \mathbf{r} + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
	    \label{eq:bidirectional_schur_po_solution}
	    \end{aligned}
	\end{equation}
	with complexity\footnoteref{foot:ic} given by Equation \ref{eq:complexity_schur_bidirectional2}.
\end{itemize}
where, in both cases, we have used $\mathbf{r} = \mathbf{i}[\mathbf{p}] - \bar{\mathbf{a}}$.


\subsubsection*{Alternated}
\label{sec:gauss_newton_alternated}

Instead of solving the problem simultaneously with respect to all parameters, we can update one set of parameters at a time while keeping the other sets fixed. In the optimization literature, this procedure is known as alternated optimization \cite{DelaTorre2012}.

More specifically, using \emph{asymmetric} composition we can alternate between updating $\Delta\mathbf{c}$ given the previous $\Delta\mathbf{p}^*$ and then update $\Delta\mathbf{p}$ given the updated $\Delta\mathbf{c}^*$ in an alternate manner. Taking advantage of the structure of the problem defined by Equation \ref{eq:asymmetric_structure}, we can obtain the following system of equations:
\begin{equation}
    \begin{aligned}
        -\Delta\mathbf{c} + \mathbf{A}^T \mathbf{J}_{\mathbf{t}} \Delta\mathbf{p} & = -\mathbf{A}^T \mathbf{r}_a
        \\
        \mathbf{J}_{\mathbf{t}}^T \mathbf{A} \Delta\mathbf{c} - \mathbf{J}_{\mathbf{t}}^T \mathbf{J}_{\mathbf{t}} \Delta\mathbf{p} & = \mathbf{J}_\mathbf{t}^T \mathbf{r}_a
    \label{eq:asymmetric_alt_system}
    \end{aligned}
\end{equation}
which we can rewrite as:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{c} & = \mathbf{A}^T \left( \mathbf{r}_a + \mathbf{J}_{\mathbf{t}} \Delta\mathbf{p}^* \right)
        \\
        \Delta\mathbf{p}& = -\left(\mathbf{J}_{\mathbf{t}}^T\mathbf{J}_{\mathbf{t}}\right)^{-1} \mathbf{J}_{\mathbf{t}}^T \left( \mathbf{r}_a + \mathbf{A} \Delta\mathbf{c}^* \right)
        \label{eq:asymmetric_alt_solution}
    \end{aligned}
\end{equation}
in order to obtain the analytical expression for the previous alternated update rules. The complexity at each iteration dominated by:
\begin{equation}
    \begin{aligned}
        O(\underbrace{n^2F + n^3}_{(\mathbf{J}_{\mathbf{t}}^T\mathbf{J}_{\mathbf{t}})^{-1}})
    \label{eq:complexity_alternated_asymmetric}
    \end{aligned}
\end{equation}

In the case of \emph{bidirectional} composition we can proceed in two different ways:
\begin{inparaenum}[\itshape a\upshape)]
\item update $\Delta\mathbf{c}$ given the previous $\Delta\mathbf{p}^*$ and $\Delta\mathbf{q}^*$ and then update $(\Delta\mathbf{p}^T, \Delta\mathbf{q}^T)^T$ from the updated $\Delta\mathbf{c}^*$, or
\item update $\Delta\mathbf{c}$ given the previous $\Delta\mathbf{p}^*$ and $\Delta\mathbf{q}^*$, then  $\Delta\mathbf{p}$ given the updated $\Delta\mathbf{c}^*$ and the previous $\Delta\mathbf{q}^*$ and, finally, $\Delta\mathbf{q}$ given the updated $\Delta\mathbf{c}^*$ and $\Delta\mathbf{p}^*$.
\end{inparaenum}

From Equation \ref{eq:bidirectional_structure}, we can derive the following system of equations:
\begin{equation}
    \begin{aligned}
        -\Delta\mathbf{c} + \mathbf{A}^T \mathbf{J}_\mathbf{i} \Delta\mathbf{p} - \mathbf{A}^T \mathbf{J}_\mathbf{a} \Delta\mathbf{q} & = -\mathbf{A}^T \mathbf{r}_b
        \\
        \mathbf{J}_{\mathbf{i}}^T \mathbf{A} \Delta\mathbf{c} - \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_\mathbf{i} \Delta\mathbf{p} + \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_\mathbf{a} \Delta\mathbf{q} & = \mathbf{J}_{\mathbf{i}}^T \mathbf{r}_b
        \\
        -\mathbf{J}_{\mathbf{a}}^T \mathbf{A} \Delta\mathbf{c} + \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_\mathbf{i} \Delta\mathbf{p} - \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_\mathbf{a} \Delta\mathbf{q} & = -\mathbf{J}_{\mathbf{a}}^T \mathbf{r}_b
    \label{eq:bidirectional_alt_system}
    \end{aligned}
\end{equation}
from which we can define the alternated update rules for the first of the previous two options:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{c}& = \mathbf{A}^T \left( \mathbf{r}_b + \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* - \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
        \\
        \begin{pmatrix}
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix} & =
        \begin{pmatrix}
            -\mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{a}}
            \\
            \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{i}} & -\mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{a}}
            \\
        \end{pmatrix}^{-1}
        \begin{pmatrix}
            \mathbf{J}_{\mathbf{i}}^T
            \\
            -\mathbf{J}_{\mathbf{a}}^T
        \end{pmatrix} \left(\mathbf{r}_b - \mathbf{A} \Delta\mathbf{c}^*\right)
        \label{eq:bidirectional_alt_solution1}
    \end{aligned}
\end{equation}
with complexity:
\begin{equation}
    \begin{aligned}
        O(\underbrace{(2n)^2F + (2n)^3}_{
        \begin{pmatrix}
            \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{a}}
            \\
            \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{i}} & \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{a}}
            \\
        \end{pmatrix}^{-1}
        })
    \label{eq:complexity_alternated_bidirectional1}
    \end{aligned}
\end{equation}
The rules for the second options is:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{c} & = \mathbf{A}^T \left( \mathbf{r}_b + \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* - \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
        \\
        \Delta\mathbf{p} & = -(\mathbf{J}_{\mathbf{i}}^T\mathbf{J}_{\mathbf{i}})^{-1} \mathbf{J}_{\mathbf{i}}^T \left( \mathbf{r}_b - \mathbf{A} \Delta\mathbf{c}^* - \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
        \\
        \Delta\mathbf{q} & = -(\mathbf{J}_{\mathbf{a}}^T\mathbf{J}_{\mathbf{a}})^{-1} \mathbf{J}_{\mathbf{a}}^T \left( \mathbf{r}_b - \mathbf{A} \Delta\mathbf{c}^* + \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* \right)
        \label{eq:bidirectional_alt_solution2}
    \end{aligned}
\end{equation}
and their complexity is dominated by:
\begin{equation}
    \begin{aligned}
        O(\underbrace{2n^2F + 2n^3}_{(\mathbf{J}_{\mathbf{i}}^T\mathbf{J}_{\mathbf{i}})^{-1} \, \& \, (\mathbf{J}_{\mathbf{a}}^T\mathbf{J}_{\mathbf{a}})^{-1}})
    \label{eq:complexity_alternated_bidirectional2}
    \end{aligned}
\end{equation}

On the other hand, the alternated update rules using the project-out cost function are:
\begin{itemize}
	\item For \emph{asymmetric} composition:
	There is no proper alternated rule because the project-out cost function only depends on one set of parameters, $\Delta \mathbf{p}$.
	\item For \emph{bidirectional} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{q} & = \left( \mathbf{J}_{\bar{\mathbf{a}}}^T\bar{\mathbf{A}}\mathbf{J}_{\bar{\mathbf{a}}} \right)^{-1} \mathbf{J}_{\bar{\mathbf{a}}}^T\bar{\mathbf{A}} \left( \mathbf{r} - \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* \right)
	        \\
	        \Delta \mathbf{p} & = -\left( \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}} \right)^{-1} \mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}} \left( \mathbf{r} + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
	    \label{eq:bidirectional_alternated_po_solution}
	    \end{aligned}
	\end{equation}
	with equivalent complexity to the one given by Equation \ref{eq:complexity_schur_asymmetric} because the term $\left( \mathbf{J}_{\bar{\mathbf{a}}}^T \bar{\mathbf{A}} \mathbf{J}_{\bar{\mathbf{a}}} \right)^{-1} \mathbf{J}_{\bar{\mathbf{a}}}^T \bar{\mathbf{A}}$ can be precomputed in this case.
\end{itemize}

Note that all previous alternated update rules, Equations \ref{eq:asymmetric_alt_solution}, \ref{eq:bidirectional_alt_solution1}, \ref{eq:bidirectional_alt_solution2} and \ref{eq:bidirectional_alternated_po_solution}, are similar but slightly different from their simultaneous counterparts, Equations \ref{eq:asymmetric_schur_solution1} and \ref{eq:asymmetric_schur_solution2}, \ref{eq:bidirectional_schur_solution1} and \ref{eq:bidirectional_schur_solution2}, \ref{eq:bidirectional_schur_solution3} and \ref{eq:bidirectional_schur_solution4}, and \ref{eq:bidirectional_schur_po_solution}.


\subsubsection*{Efficient Second-order Minimization (ESM)}
\label{sec:gauss_newton_alternated}

The use of \emph{asymmetric} composition together with the Gauss-Newton method has been proven to naturally lead to Efficient Second order Minimization (ESM) algorithms in the related field of parametric image alignment \cite{Malis2004, Benhimane2004, Megret2008, Megret2010}. Following a similar line of reasoning, in this subsection we show that asymmetric Gauss-Newton algorithms for fitting AAMs can also be interpreted as ESM algorithms with respect to the incremental warp $\Delta \mathbf{p}$.

In order to show the previous relationship we will make use of the simplified data term\footnote{Notice that similar derivations can also be obtained using the SSD and project-out data terms, but we use the simplified one here to favor clarity.} introduced by Equation \ref{eq:ssd_shape}. Using \emph{forward} composition, the optimization problem defined by:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{p}^* & = \underset{\Delta \mathbf{p}}{\mathrm{arg\,min\;}} \frac{1}{2} \mathbf{r}_f^T\bar{\mathbf{A}}\mathbf{r}_f
    \label{eq:po_forward}
    \end{aligned}
\end{equation}
where the forward residual $\mathbf{r}_f$ is defined as:
\begin{equation}
    \begin{aligned}
		\mathbf{r}_f & = \mathbf{i}[\mathbf{p}_{k-1}^* \circ \Delta \mathbf{p}] - \bar{\mathbf{a}}
    \label{eq:po_forward_residual}
    \end{aligned}
\end{equation}
As seen before, Gauss-Newton solves the previous optimization problem by first performing a \emph{first} order Taylor expansion of the residual around $\Delta \mathbf{p}$:
\begin{equation}
    \begin{aligned}
		\hat{\mathbf{r}}_f(\Delta\mathbf{p}) & = \mathbf{r}_f + \frac{\partial \mathbf{r}_f}{\partial\Delta \mathbf{p}}\Delta\mathbf{p} + \underbrace{O_{\mathbf{r}_f}(\Delta\mathbf{p}^2)}_{\textrm{reminder}}
		\\
		& = \mathbf{i}[\mathbf{p}_{k-1}^*] - \bar{\mathbf{a}} + \mathbf{J}_\mathbf{i}\Delta\mathbf{p} + O_{\mathbf{r}_f}(\Delta\mathbf{p}^2)
    \label{eq:po_forward_residual_taylor}
    \end{aligned}
\end{equation}
and then solving the following approximation of the original problem:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{p}^* & = \underset{\Delta\mathbf{p}}{\mathrm{arg\,min\;}} \frac{1}{2} \hat{\mathbf{r}}_f^T\hat{\mathbf{r}}_f
    \label{eq:po_forward_taylor}
    \end{aligned}
\end{equation}

However, note that, instead of performing a first order Taylor expansion, we can also perform a \emph{second} order Taylor expansion of the residual:
\begin{equation}
    \begin{aligned}
		\check{\mathbf{r}}_f(\Delta\mathbf{p}) & = \mathbf{r}_f + \frac{\partial \mathbf{r}_f}{\partial\Delta \mathbf{p}}\Delta\mathbf{p} \,+
		\\
		& \quad \, \frac{1}{2} \Delta\mathbf{p}^T\frac{\partial^2 \mathbf{r}_f}{\partial^2\Delta \mathbf{p}}\Delta\mathbf{p} + O_{\mathbf{r}_f}(\Delta\mathbf{p}^3)
		\\
		& = \mathbf{i}[\mathbf{p}_{k-1}^*] - \bar{\mathbf{a}} + \mathbf{J}_\mathbf{i}\Delta\mathbf{p} \, +
		\\
		& \quad \, \frac{1}{2} \Delta\mathbf{p}^T\mathbf{H}_\mathbf{i}\Delta\mathbf{p} + O_{\mathbf{r}_f}(\Delta\mathbf{p}^3)
    \label{eq:po_forward_residual_taylor2}
    \end{aligned}
\end{equation}
Then, given the second main assumption behind AAMs (Equation \ref{eq:aam_2}) the following approximation must hold:
\begin{equation}
	\begin{aligned}
		\nabla\mathbf{i}[\mathbf{p}] \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}} & \approx \nabla\mathbf{a} \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}}
		\\
		\mathbf{J}_\mathbf{i} & \approx \mathbf{J}_\mathbf{a}
		\label{eq:jacobian_aproximation}
	\end{aligned}
\end{equation}
and because the previous $\mathbf{J}_\mathbf{i}$ and $\mathbf{J}_\mathbf{a}$ are functions of $\Delta\mathbf{p}$ we can perform a first oder Taylor expansion around the former to obtain:
\begin{equation}
	\begin{aligned}
	\mathbf{J}_\mathbf{i} (\Delta\mathbf{p}) & \approx \mathbf{J}_\mathbf{i} + \Delta\mathbf{p}^T \frac{\partial\mathbf{J}_\mathbf{i}}{\partial\Delta\mathbf{p}} + \underbrace{O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2)}_{\textrm{reminder}}
	\\
	& \approx \mathbf{J}_\mathbf{i} + \Delta\mathbf{p}^T \mathbf{H}_\mathbf{i} + O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2)
	\\
	\mathbf{J}_\mathbf{a} & \approx  \mathbf{J}_\mathbf{i} + \Delta\mathbf{p}^T \mathbf{H}_\mathbf{i} + O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2)
	\\
	\Delta\mathbf{p}^T \mathbf{H}_\mathbf{i} & \approx \mathbf{J}_\mathbf{a} - \mathbf{J}_\mathbf{i} - O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2)
	\label{eq:jacobian_taylor}
	\end{aligned}
\end{equation}

Finally, substituting the previous approximation for $\Delta\mathbf{p}^T \mathbf{H}_\mathbf{i}$ into equation \ref{eq:po_forward_residual_taylor2} we have:
\begin{equation}
    \begin{aligned}
		\check{\mathbf{r}}_f(\Delta\mathbf{p}) & = \mathbf{i}[\mathbf{p}_{k-1}^*] - \bar{\mathbf{a}} + \mathbf{J}_\mathbf{i}\Delta\mathbf{p} \, +
		\\
		& \quad \, \frac{1}{2} \Delta\mathbf{p}^T\mathbf{H}_\mathbf{i}\Delta\mathbf{p} + O_{\mathbf{r}_f}(\Delta\mathbf{p}^3)
		\\
		& = \mathbf{i}[\mathbf{p}_{k-1}^*] - \bar{\mathbf{a}} + \mathbf{J}_\mathbf{i}\Delta\mathbf{p} \, +
		\\
		& \quad \, \frac{1}{2} \left( \mathbf{J}_\mathbf{a} - \mathbf{J}_\mathbf{i} - O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2) \right) \Delta\mathbf{p} \, +
		\\
		& \quad \, O_{\mathbf{r}_f}(\Delta\mathbf{p}^3)
		\\
		& = \mathbf{i}[\mathbf{p}_{k-1}^*] - \bar{\mathbf{a}} + \frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{a} \right) \Delta\mathbf{p} \, +
		\\
		& \quad \, O_{\textrm{total}}(\Delta\mathbf{p}^3)
    \label{eq:po_asymmetric_residual_approximation}
    \end{aligned}
\end{equation}
where the total reminder is cubic with respect to $\Delta \mathbf{p}$:
\begin{equation}
    \begin{aligned}
		O_{\textrm{total}}(\Delta\mathbf{p}^3) = O_{\mathbf{r}_f}(\Delta\mathbf{p}^3) - O_{\mathbf{J}_\mathbf{i}}(\Delta\mathbf{p}^2) \Delta\mathbf{p}
    \label{eq:po_asymmetric_residual_approximation}
    \end{aligned}
\end{equation}
The previous expression constitutes a true second order approximation of the forward residual $\mathbf{r}_f$ where the term $\frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{a} \right)$ is equivalent to the asymmetric Jacobian in Equation \ref{eq:asymmetric_ssd_taylor} when $\alpha = \beta = 0.5$:
\begin{equation}
    \begin{aligned}
		\frac{1}{2} \left( \mathbf{J}_\mathbf{i} + \mathbf{J}_\mathbf{a} \right) & = \left( \frac{1}{2} \mathbf{J}_\mathbf{i} + \frac{1}{2} \mathbf{J}_\mathbf{a} \right)
		\\
		& = \left( \frac{1}{2} \nabla \mathbf{i}[\mathbf{p}] \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}} + \frac{1}{2} \nabla \mathbf{a} \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}} \right)
		\\
		& = \left( \frac{1}{2} \nabla \mathbf{i}[\mathbf{p}] + \frac{1}{2} \nabla \mathbf{a} \right) \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}}
		\\
		& = \left( \nabla \mathbf{t} \right) \frac{\partial\mathcal{W}}{\partial\Delta\mathbf{p}}
		\\
		& = \mathbf{J}_\mathbf{t}
    \label{eq:equivalent_jacobians}
    \end{aligned}
\end{equation}
and, consequently, asymmetric Gauss- Newton algorithms for fitting AAMs can be viewed as ESM algorithms that only require first order partial derivatives of the residual.


\subsubsection{Newton}
\label{sec:newton}

The Newton algorithm performs a second order Taylor expansion of the entire data term $\mathcal{D}$:
\begin{equation}
    \begin{aligned}
		\mathcal{D}(\Delta \boldsymbol{\ell}) & \approx \hat{\mathcal{D}}(\Delta \boldsymbol{\ell})
		\\
		& \approx \mathcal{D} + \frac{\partial \mathcal{D}}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell} + \frac{1}{2}\Delta \boldsymbol{\ell}^T \frac{\partial^2 \mathcal{D}}{\partial^2 \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell}
    \label{eq:newton_taylor}
    \end{aligned}
\end{equation}
and solves the approximate problem:
\begin{equation}
    \begin{aligned}
        \Delta \boldsymbol{\ell}^* & = \underset{\Delta \boldsymbol{\ell}}{\mathrm{arg\,min\;}} \hat{\mathcal{D}}
    \label{eq:newton_optimization_problem}
    \end{aligned}
\end{equation}

Assuming \emph{asymmetric} composition, the previous data term is define as:
\begin{equation}
    \begin{aligned}
		\mathcal{D}_a(\Delta \boldsymbol{\ell}) & = \frac{1}{2}\mathbf{r}_a^T \mathbf{r}_a
    \label{eq:asymmetric_data}
    \end{aligned}
\end{equation}
and the matrix containing the first order partial derivatives with respect to the parameters, i.e. the data term's \emph{Jacobian}, can be written as:
\begin{equation}
    \begin{aligned}
		\frac{\partial \mathcal{D}_a}{\partial \Delta \boldsymbol{\ell}} & = \left( \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{c}}, \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{p}} \right)
		\\
		& = \left( -\mathbf{A}^T \mathbf{r}_a, \mathbf{J}_{\mathbf{t}}^T \mathbf{r}_a \right)
    \label{eq:asymmetric_newton_jacobian}
    \end{aligned}
\end{equation}
On the other hand, the matrix $\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \boldsymbol{\ell}}$ of the second order partial derivatives, i.e. the \emph{Hessian} of the data term, takes the following form:
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \boldsymbol{\ell}} & =
		\begin{pmatrix}
			\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{c}} & \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}}
			\\
			\frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} & \frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}}
		\end{pmatrix}
    \label{eq:asymmetric_newton_hessian}
    \end{aligned}
\end{equation}
Note that the Hessian matrix is, by definition, symmetric and its individual terms are defined as follows:
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{c}} & = \frac{\partial -\mathbf{A}^T \mathbf{r}_a}{\partial \Delta \mathbf{c}}
		\\
		& = -\mathbf{A}^T \frac{\partial \mathbf{r}_a}{\partial \Delta \mathbf{c}}
		\\
		& = \underbrace{\mathbf{A}^T \mathbf{A}}_{\mathbf{I}}
    \label{eq:asymmetric_hessian_term1}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} & = \frac{\partial -\mathbf{A}^T \mathbf{r}_a}{\partial \Delta \mathbf{p}}
		\\
		& = \frac{\partial -\mathbf{A}^T}{\partial \Delta \mathbf{p}} \mathbf{r}_a - \mathbf{A}^T \frac{\partial\mathbf{r}_a}{\partial \Delta \mathbf{p}}
		\\
		& = -\beta \mathbf{J}_\mathbf{A}^T \mathbf{r}_a - \mathbf{A}^T \mathbf{J}_{\mathbf{t}}
    \label{eq:asymmetric_hessian_term2}
    \end{aligned}
\end{equation}
where we have defined $\mathbf{J}_\mathbf{A} = [\nabla \mathbf{a}_1, \cdots, \nabla \mathbf{a}_m]^T \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}}$.
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}} & =  \frac{\partial \mathbf{J}_{\mathbf{t}}^T \mathbf{r}_a}{\partial \Delta \mathbf{p}}
		\\
		& = \frac{\partial \mathbf{J}_{\mathbf{t}}^T}{\partial \Delta \mathbf{p}} \mathbf{r}_a + \mathbf{J}_{\mathbf{t}}^T \frac{\partial \mathbf{r}_a}{\partial \Delta \mathbf{p}}
		\\
		& = \left( \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}}^T \nabla^2 \mathbf{t} \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}} + \underbrace{\nabla \mathbf{t} \overbrace{\frac{\partial^2 \mathcal{W}}{\partial^2 \mathbf{p}}}^{\mathbf{0}}}_{\mathbf{0}} \right) \mathbf{r}_a +
		\\
		& \qquad \, \mathbf{J}_{\mathbf{t}}^T \mathbf{J}_{\mathbf{t}}
		\\
		& = \left( \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}}^T \nabla^2 \mathbf{t} \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}} \right) \mathbf{r}_a + \mathbf{J}_{\mathbf{t}}^T \mathbf{J}_{\mathbf{t}}
    \label{eq:asymmetric_hessian_term3}
    \end{aligned}
\end{equation}

A similar derivation can be obtained for \emph{bidirectional} composition where, as expected, the data term is define as:
\begin{equation}
    \begin{aligned}
		\mathcal{D}_b(\Delta \boldsymbol{\ell}) & = \frac{1}{2}\mathbf{r}_b^T \mathbf{r}_b
    \label{eq:bidirectional_data}
    \end{aligned}
\end{equation}
In this case, the Jacobian matrix writes:
\begin{equation}
    \begin{aligned}
		\frac{\partial \mathcal{D}_b}{\partial \Delta \boldsymbol{\ell}} & = \left( \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}}, \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{p}}, \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{q}} \right)
		\\
		& = \left( -\mathbf{A}^T \mathbf{r}_a, \mathbf{J}_{\mathbf{i}}^T \mathbf{r}_a, -\mathbf{J}_{\mathbf{a}}^T \mathbf{r}_a \right)
    \label{eq:bidirectional_newton_jacobian}
    \end{aligned}
\end{equation}
and the Hessian matrix takes the following form:
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \boldsymbol{\ell}} & =
		\begin{pmatrix}
			\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{c}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}}
			\\
			\frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} & \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{q}}
			\\
			\frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{c}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{q}}
			& \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}}
		\end{pmatrix}
    \label{eq:bidirectional_newton_hessian}
    \end{aligned}
\end{equation}
As before, the previous matrix is symmetric and its individual terms are defined as follows:
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{c}} & = \frac{\partial -\mathbf{A}^T \mathbf{r}_b}{\partial \Delta \mathbf{c}}
		\\
		& = -\mathbf{A}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{c}}
		\\
		& = \underbrace{\mathbf{A}^T \mathbf{A}}_{\mathbf{I}}
    \label{eq:bidirectional_hessian_term1}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} & = \frac{\partial -\mathbf{A}^T \mathbf{r}_b}{\partial \Delta \mathbf{p}}
		\\
		& = -\mathbf{A}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{p}}
		\\
		& = -\mathbf{A}^T \mathbf{J}_{\mathbf{i}}
    \label{eq:bidirectional_hessian_term2}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}} & =  \frac{\partial -\mathbf{A}^T \mathbf{r}_b}{\partial \Delta \mathbf{q}}
		\\
		&= \frac{\partial -\mathbf{A}^T}{\partial \Delta \mathbf{q}} \mathbf{r}_b - \mathbf{A}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{q}}
		\\
		& = -\mathbf{J}_{\mathbf{A}}^T \mathbf{r}_b + \mathbf{A}^T \mathbf{J}_{\mathbf{a}}
    \label{eq:bidirectional_hessian_term3}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}} & =  \frac{\partial \mathbf{J}_{\mathbf{i}}^T \mathbf{r}_b}{\partial \Delta \mathbf{p}}
		\\
		& = \frac{\partial \mathbf{J}_{\mathbf{i}}^T}{\partial \Delta \mathbf{p}} \mathbf{r}_b + \mathbf{J}_{\mathbf{i}}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{p}}
		\\
		& = \left( \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}}^T \nabla^2 \mathbf{i}[\mathbf{p}] \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{p}} \right) \mathbf{r}_b + \mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{i}}
    \label{q:bidirectional_hessian_term4}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{q}} & =  \frac{\partial \mathbf{J}_{\mathbf{i}}^T \mathbf{r}_b}{\partial \Delta \mathbf{q}}
		\\
		& = -\mathbf{J}_{\mathbf{i}}^T \mathbf{J}_{\mathbf{a}}
    \label{eq:bidirectional_hessian_term5}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
		\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}} & =  \frac{\partial -\mathbf{J}_{\mathbf{a}}^T \mathbf{r}_b}{\partial \Delta \mathbf{q}}
		\\
		& = \frac{\partial -\mathbf{J}_{\mathbf{a}}^T}{\partial \Delta \mathbf{q}} \mathbf{r}_b - \mathbf{J}_{\mathbf{a}}^T \frac{\partial \mathbf{r}_b}{\partial \Delta \mathbf{q}}
		\\
		& = -\left( \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{q}}^T \nabla^2 (\mathbf{a} + \mathbf{A}\mathbf{c}) \frac{\partial\mathcal{W}}{\partial \Delta \mathbf{q}} \right) \mathbf{r}_b + \mathbf{J}_{\mathbf{a}}^T \mathbf{J}_{\mathbf{a}}
    \label{q:bidirectional_hessian_term6}
    \end{aligned}
\end{equation}


\subsubsection*{Simultaneous}
\label{sec:newton_simultaneous}

Using the Newton method we can solve for all parameters simultaneously by equating the partial derivative of Equation \ref{eq:newton_optimization_problem} to $0$:
\begin{equation}
    \begin{aligned}
    	0 & = \frac{\partial\hat{\mathcal{D}}}{\partial \Delta \boldsymbol{\ell}}
    	\\
    	& = \frac{\partial \left(\mathcal{D} + \frac{\partial \mathcal{D}}{\partial \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell} + \frac{1}{2} \Delta \boldsymbol{\ell}^T \frac{\partial^2 \mathcal{D}}{\partial^2 \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell} \right)}{\partial \Delta \boldsymbol{\ell}}
    	\\
		& = \frac{\partial \mathcal{D}}{\partial \Delta \boldsymbol{\ell}} + \frac{\partial^2 \mathcal{D}}{\partial^2 \Delta \boldsymbol{\ell}} \Delta \boldsymbol{\ell}
    \label{eq:ssd_bc}
    \end{aligned}
\end{equation}
with the solution given by:
\begin{equation}
    \begin{aligned}
    	\Delta \boldsymbol{\ell}^* & = -\frac{\partial^2 \mathcal{D}}{\partial^2 \Delta \boldsymbol{\ell}}^{-1} \frac{\partial \mathcal{D}}{\partial \Delta \boldsymbol{\ell}}
    \label{eq:ssd_bc}
    \end{aligned}
\end{equation}

Note that, similar to the Gauss-Newton method, the complexity of inverting the Hessian matrix $\frac{\partial^2 \mathcal{D}}{\partial^2 \Delta \boldsymbol{\ell}}$ is $O((m+2n)^3)$ for asymmetric composition and $O((2n + m)^3)$ for bidirectional composition. As shown by by Kossaifi et al. \cite{Kossaifi2014}\footnote{In \cite{Kossaifi2014}, Kossaifi et al. applied the Schur complement to the Newton method using \emph{only} inverse composition while we apply it here using the more general \emph{asymmetric} (which includes \emph{forward}, \emph{inverse} and \emph{symmetric}) and \emph{bidirectional} compositions.}, we can take advantage of the structure of the Hessian in Equations \ref{eq:asymmetric_newton_hessian} and \ref{eq:bidirectional_newton_hessian} and apply the Schur complement to obtain more efficient solutions.

The solutions for $\Delta\mathbf{p}$ and $\Delta\mathbf{c}$ using \emph{asymmetric} composition are given by the following expressions:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{p} & = \left(\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \Delta \mathbf{p}} \right)^{-1}
        \\
        & \quad \, \left( \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \Delta \mathbf{c}} \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{c}} \right)
        % & = \left( \mathbf{H}_{\mathbf{t}} - \left( \beta\mathbf{J}^T_{\mathbf{A}}\mathbf{r}_a + \mathbf{A}^T\mathbf{J}_{\mathbf{t}} \right)^T \left( \beta\mathbf{J}^T_{\mathbf{A}}\mathbf{r}_a + \mathbf{A}^T\mathbf{J}_{\mathbf{t}} \right) \right)^{-1}
        % \\
        % & \quad \, \left( \mathbf{J}_t \bar{\mathbf{A}} \mathbf{r}_a - \beta \mathbf{r}_a^T\mathbf{J}_{\mathbf{A}}\mathbf{A}^T\mathbf{r}_a \right)
    	\\
        \Delta \mathbf{c} & = \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^*
        % \\
        % & = \mathbf{A}^T \left( \left(\mathbf{I} - \beta \mathbf{J}_{\mathbf{A}} \right) \mathbf{r}_a - \mathbf{J}_{\mathbf{t}} \Delta \mathbf{p} \right)
    \label{eq:asymmetric_newton_schur_solutions}
    \end{aligned}
\end{equation}
with complexity:
\begin{equation}
    \begin{aligned}
        O(
        \underbrace{nmF}_{\frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}}}
        +
        \underbrace{n^2m}_{\frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}}}
        +
        \underbrace{2n^2F}_{\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}}}
        +
        \underbrace{n^3}_{\mathbf{H}^{-1}}
        )
    \label{eq:complexity_sim_asymmetric_newton}
    \end{aligned}
\end{equation}
where we have defined $\mathbf{H} =\left(\frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \Delta \mathbf{p}} \right)^{-1}$ in order to unclutter the notation.

On the other hand, the solutions for \emph{bidirectional} composition are given either by:
\begin{equation}
    \begin{aligned}
        \begin{pmatrix}
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix} & =
        \begin{pmatrix}
            \mathbf{V} & \mathbf{W}^T
            \\
            \mathbf{W} & \mathbf{U}
            \\
        \end{pmatrix}^{-1}
        \begin{pmatrix}
            \mathbf{v}
            \\
            \mathbf{u}
        \end{pmatrix}
        \\
        \Delta \mathbf{c} & = \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^* - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}} \Delta \mathbf{q}^*
    \label{eq:bidirectional_newton_schur_solutions1}
    \end{aligned}
\end{equation}
or
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{p} & = \left( \mathbf{U} - \mathbf{W} \mathbf{V}^{-1} \mathbf{W}^T \right)^{-1} \left(\mathbf{u} -  \mathbf{W} \mathbf{V}^{-1}\mathbf{v} \right)
    	\\
        \Delta \mathbf{p} & = \mathbf{V}^{-1} \left( \mathbf{v} - \mathbf{W}^T \Delta\mathbf{q}^*\right)
    	\\
        \Delta \mathbf{c} & = \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^* - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}} \Delta \mathbf{q}^*
    \label{eq:bidirectional_newton_schur_solutions2}
    \end{aligned}
\end{equation}
where we have defined the following auxiliary matrices
\begin{equation}
    \begin{aligned}
    	\mathbf{V} & = \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \Delta \mathbf{p}}
    	\\
    	\mathbf{W} & = \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \Delta \mathbf{p}}
    	\\
    	\mathbf{U} & = \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \Delta \mathbf{c}} \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \Delta \mathbf{q}}
    \label{eq:auxiliar_matrixes}
    \end{aligned}
\end{equation}
and vectors
\begin{equation}
    \begin{aligned}
    	\mathbf{v} & = \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \Delta \mathbf{c}} \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}}
    	\\
    	\mathbf{u} & = \frac{\partial \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \Delta \mathbf{c}} \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}}
    \label{eq:auxiliar_matrixes}
    \end{aligned}
\end{equation}
The complexity of the previous solutions is of:
\begin{equation}
    \begin{aligned}
        O( &
        \underbrace{nmF}_{\mathbf{v}}
        +
        \underbrace{2nmF}_{\mathbf{u}}
        +
        \underbrace{4n^2F + 2n^2m}_{\mathbf{U} \, \& \, \mathbf{V}}
        +
        \\
        &
        \underbrace{2n^2F + n^2m}_{\mathbf{W}}
        +
        \underbrace{(2n)^3}_{
        \begin{pmatrix}
            \mathbf{V} & \mathbf{W}^T
            \\
            \mathbf{W} & \mathbf{U}
            \\
        \end{pmatrix}^{-1}}
        )
    \label{eq:complexity_sim_bidirectional2_newton}
    \end{aligned}
\end{equation}
and
\begin{equation}
    \begin{aligned}
        O( &
        \underbrace{nmF}_{\mathbf{v}}
        +
        \underbrace{2nmF}_{\mathbf{u}}
        +
        \\
        &
        \underbrace{4n^2F + 2n^2m}_{\mathbf{U} \, \& \, \mathbf{V}}
        +
        \underbrace{2n^2F + n^2m}_{\mathbf{W}}
        +
        \\
        &
        \underbrace{4n^3}_{\mathbf{V}^{-1},  \, \& \, \left( \mathbf{U} - \mathbf{W} \mathbf{V}^{-1} \mathbf{W}^T \right)^{-1} }
        )
    \label{eq:complexity_sim_bidirectional2_newton}
    \end{aligned}
\end{equation}
respectively.

The solutions using the project-out cost function are:
\begin{itemize}
	\item For \emph{asymmetric} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{p} & = -\left( \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}^T \nabla^2\mathbf{t} \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}\bar{\mathbf{A}}\mathbf{r} + \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^{-1}
	        \\
	        & \quad \, \mathbf{J}_{\mathbf{t}}^T\bar{\mathbf{A}}\mathbf{r}
	    \label{eq:asymmetric_newton_po_solution}
	    \end{aligned}
	\end{equation}
	with complexity\footnote{\label{foot:ic_newton}In practice, the solutions for the project-out cost function can also be computed slightly faster because they do not need to explicitly solve for $\Delta\mathbf{c}$. However, in this case, using \emph{inverse} composition we can only precompute terms of the form $\mathbf{J}^T\mathbf{U}$ and  $\mathbf{J}^T\mathbf{U}\mathbf{J}$ but not the entire $\mathbf{H}^{-1}\mathbf{J}^T\mathbf{U}$ because of the explicit dependence between $\mathbf{H}$ and the current residual $\mathbf{r}$.} given by Equation \ref{eq:complexity_sim_asymmetric_newton}.

	\item For \emph{bidirectional} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{q} & = \left( \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}^T \nabla^2\bar{\mathbf{a}} \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}\bar{\mathbf{A}}\mathbf{r} + \mathbf{J}_{\bar{\mathbf{a}}}^T\tilde{\mathbf{P}}\mathbf{J}_{\bar{\mathbf{a}}}\right)^{-1}
	        \\
	        & \quad \, \mathbf{J}_{\bar{\mathbf{a}}}^T\tilde{\mathbf{P}}\mathbf{r}
	        \\
	        \Delta \mathbf{p} & = -\mathbf{H}_\mathbf{i}^{-1} \mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}} \left( \mathbf{r} + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
	    \label{eq:bidirectional_newton_po_solution}
	    \end{aligned}
	\end{equation}
	where the projection operator $\tilde{\mathbf{P}}$ is defined as:
	\begin{equation}
	    \begin{aligned}
			\tilde{\mathbf{P}} &= \bar{\mathbf{A}} - \bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}}^T \mathbf{H}_\mathbf{i}^{-1} \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}
			\label{eq:bidirectional_projection}
	    \end{aligned}
	\end{equation}
	and where we have defined:
	\begin{equation}
	    \begin{aligned}
			\mathbf{H}_\mathbf{i} = \left( \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}^T \nabla^2\mathbf{i}[\mathbf{p}] \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}\bar{\mathbf{A}}\mathbf{r} + \mathbf{J}_{\mathbf{i}}^T\bar{\mathbf{A}}\mathbf{J}_{\mathbf{i}}^T \right)
	    \end{aligned}
    \end{equation} to unclutter the notation. The complexity per iteration\footnoteref{foot:ic_newton} is given by Equation \ref{eq:complexity_sim_bidirectional2_newton}.
\end{itemize}

Note that, the derivations of the previous solutions, for both types of composition, are analogous to the ones shown in Section \ref{sec:gauss_newton_simultaneous} for the Gauss-Newton method and, consequently, have been omitted here.


\subsubsection*{Alternated}
\label{sec:newton_alternated}

Alternated optimization rules can also be derived for the Newton method following the strategy shown in Section \ref{sec:gauss_newton_alternated} for the Gauss-Newton method. Again, we will simply provide the update rules for both types of composition and omit the details of their full derivation.

For \emph{asymmetric} composition the alternated rules are defined as:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{c} & = \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^*
        \\
        \Delta \mathbf{p} & = \frac{\partial^2 \mathcal{D}_a}{\partial^2 \Delta \mathbf{p}}^{-1} \left( \frac{\partial \mathcal{D}_a}{\partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} \Delta \mathbf{c}^* \right)
        \label{eq:asymmetric_newton_alternated_solution}
    \end{aligned}
\end{equation}
with complexity:
\begin{equation}
    \begin{aligned}
        O(
        \underbrace{nmF}_{\frac{\partial^2 \mathcal{D}_a}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}}}
        +
        \underbrace{2n^2F + n^3}_{\frac{\partial^2 \mathcal{D}_a}{(\partial^2 \Delta \mathbf{p}})^{-1}}
        )
    \label{eq:complexity_alt_asymmetric_newton}
    \end{aligned}
\end{equation}

The alternated rules for \emph{bidirectional} composition case are given either by:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{c} & =  \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^* - \\
        & \quad \, \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}} \Delta \mathbf{q}^*
        \\
        \begin{pmatrix}
            \Delta\mathbf{p}
            \\
            \Delta\mathbf{q}
        \end{pmatrix} & =
        \begin{pmatrix}
            \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{q}}
            \\
            \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}}
            \\
        \end{pmatrix}^{-1}
        \\
        & \quad \,
        \begin{pmatrix}
            \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} \Delta \mathbf{c}^*
            \\
            \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{q}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{c}} \Delta \mathbf{c}^*
        \end{pmatrix}
        \label{eq:bidirectional_newton_alternated_solution1}
    \end{aligned}
\end{equation}
with complexity:
\begin{equation}
    \begin{aligned}
        O( &
        \underbrace{nmF}_{\frac{\partial^2\mathcal{D}}{\partial\Delta\mathbf{p}\partial\Delta\mathbf{p}}}
        +
        \underbrace{4n^2F}_{\frac{\partial^2\mathcal{D}}{\partial^2\Delta\mathbf{p}} \, \& \, \frac{\partial^2\mathcal{D}}{\partial^2\Delta\mathbf{q}}}
        +
        \\
        &
        \underbrace{(2n)^3}_{
        \begin{pmatrix}
            \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{q}}
            \\
            \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{p}} & \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}}
            \\
        \end{pmatrix}^{-1}}
        )
    \label{eq:complexity_alt_bidirectional1_newton}
    \end{aligned}
\end{equation}
or:
\begin{equation}
    \begin{aligned}
        \Delta \mathbf{c} & =  \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{c}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^* - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{c} \partial \Delta \mathbf{q}} \Delta \mathbf{q}^*
        \\
        \Delta \mathbf{p} & = \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}}^{-1}
        \\
        & \quad \left( \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{p}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{c}} \Delta \mathbf{c}^* - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{p} \partial \Delta \mathbf{q}} \Delta \mathbf{q}^* \right)
        \\
        \Delta \mathbf{q} & = \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}}^{-1}
        \\
        & \quad \left( \frac{\partial \mathcal{D}_b}{\partial \Delta \mathbf{q}} - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{c}} \Delta \mathbf{c}^* - \frac{\partial^2 \mathcal{D}_b}{\partial \Delta \mathbf{q} \partial \Delta \mathbf{p}} \Delta \mathbf{p}^* \right)
        \label{eq:bidirectional_newton_alternated_solution2}
    \end{aligned}
\end{equation}
with complexity:
\begin{equation}
    \begin{aligned}
        O( &
        \underbrace{nmF}_{\frac{\partial^2\mathcal{D}}{\partial\Delta\mathbf{p}\partial\Delta\mathbf{p}}}
        +
        \underbrace{4n^2F}_{\frac{\partial^2\mathcal{D}}{\partial^2\Delta\mathbf{p}} \, \& \, \frac{\partial^2\mathcal{D}}{\partial^2\Delta\mathbf{q}}}
        +
        \underbrace{2n^3}_{\frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{p}}^{-1} \, \& \, \frac{\partial^2 \mathcal{D}_b}{\partial^2 \Delta \mathbf{q}}^{-1} }
        )
    \label{eq:complexity_alt_bidirectional1_newton}
    \end{aligned}
\end{equation}

On the other hand, the alternated update rules for the Newton method using the project-out cost function are:
\begin{itemize}
	\item For \emph{asymmetric} composition:
	Again, there is no proper alternated rule because the project-out cost function only depends on one set of parameters, $\Delta \mathbf{p}$.
	\item For \emph{bidirectional} composition:
	\begin{equation}
	    \begin{aligned}
	        \Delta \mathbf{q} & = \mathbf{H}_\mathbf{a}^{-1} \mathbf{J}_{\bar{\mathbf{a}}}^T\bar{\mathbf{A}} \left( \mathbf{r} - \mathbf{J}_{\mathbf{i}} \Delta\mathbf{p}^* \right)
	        \\
	        \Delta \mathbf{p} & = -\mathbf{H}_\mathbf{i}^{-1} \mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}} \left( \mathbf{r} + \mathbf{J}_{\mathbf{a}} \Delta\mathbf{q}^* \right)
	    \label{eq:bidirectional_alternated_po_solution}
	    \end{aligned}
	\end{equation}
	where we have defined:
	\begin{equation}
	    \begin{aligned}
	        \mathbf{H}_\mathbf{a} = \left( \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}^T \nabla^2\bar{\mathbf{a}} \frac{\partial \mathcal{W}}{\Delta \mathbf{p}}\bar{\mathbf{A}}\mathbf{r} + \mathbf{J}_{\bar{\mathbf{a}}}^T\bar{\mathbf{A}}\mathbf{J}_{\bar{\mathbf{a}}} \right)
	    \label{eq:po_hessian_q}
	    \end{aligned}
	\end{equation}
	and the complexity at every iteration is given by the following expression complexity:
	\begin{equation}
	    \begin{aligned}
	        O(
	        \underbrace{nmF}_{\mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}}}
	        +
	        \underbrace{3n^2F + 2n^3}_{
                \mathbf{H}_\mathbf{i}^{-1}
                 \, \& \,
                 \mathbf{H}_\mathbf{a}^{-1}
                 }
	        )
	    \label{eq:complexity_po_alt_bidirectional_newton}
	    \end{aligned}
	\end{equation}
\end{itemize}


\subsubsection{Wiberg}
\label{sec:wiberg}

The idea behind the Wiberg method is similar to the one used by the alternated Gauss-Newton method, Section \ref{sec:gauss_newton_alternated}, i.e. solving for one set of parameters at a time while keeping the other sets fixed. However, Wiberg does so by rewriting the asymmetric $\mathbf{r}_a(\Delta\mathbf{c}, \Delta\mathbf{p})$ and bidirectional $\mathbf{r}_b(\Delta\mathbf{c}, \Delta\mathbf{p},\Delta\mathbf{q})$ residuals as functions that only depend on $\Delta\mathbf{p}$ and $\Delta\mathbf{q}$ respectively.

For \emph{asymmetric} composition, the residual $\bar{\mathbf{r}}_a (\Delta \mathbf{p})$ is defined as follows:
\begin{equation}
    \begin{aligned}
        \bar{\mathbf{r}}_a (\Delta \mathbf{p}) & = \mathbf{r}_a(\bar{\Delta \mathbf{c}}, \Delta \mathbf{p})
        \\
        & = \mathbf{i}[\mathbf{p} \circ \alpha \Delta \mathbf{p}] - (\mathbf{a} + \mathbf{A}(\mathbf{c} + \bar{\Delta \mathbf{c}}_a)) [\beta \Delta\mathbf{p}]
    \label{eq:asymmetric_wiberg_residual}
    \end{aligned}
\end{equation}
where the function $\bar{\Delta \mathbf{c}}_a(\Delta \mathbf{p})$ is obtained by solving for $\Delta\mathbf{c}$ while keeping $\Delta\mathbf{p}$ fixed:
\begin{equation}
    \begin{aligned}
        \bar{\Delta \mathbf{c}}_a(\Delta \mathbf{p}) & = \mathbf{A}^T \mathbf{r}_a
        \label{eq:asymmetric_wiberg_c_function}
    \end{aligned}
\end{equation}
Given the previous residual, the Wiberg method proceeds to define the following optimization problem with respect to $\Delta\mathbf{p}$:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{p}^* & = \underset{\Delta\mathbf{p}}{\mathrm{arg\,min\;}} \bar{\mathbf{r}}_a^T\bar{\mathbf{r}}_a
    \label{eq:asymmetric_wiberg_problem1}
    \end{aligned}
\end{equation}
which then solves approximately by performing a first order Taylor of the residual around the incremental warp:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{p}^* & = \underset{\Delta\mathbf{p}}{\mathrm{arg\,min\;}}  \left\| \bar{\mathbf{r}}_a(\Delta\mathbf{p}) + \frac{\partial \bar{\mathbf{r}}_a}{\partial\Delta\mathbf{p}} \Delta\mathbf{p} \right\|^2
    \label{eq:asymmetric_wiberg_problem2}
    \end{aligned}
\end{equation}
In this case, the Jacobian $\frac{\partial \bar{\mathbf{r}}}{\partial \Delta \mathbf{p}}$ can be obtain by direct application of the \emph{chain rule} and it is defined as follows:
\begin{equation}
    \begin{aligned}
        \frac{d \bar{\mathbf{r}}_a}{d \Delta \mathbf{p}} & = \frac{\partial \bar{\mathbf{r}}_a}{\partial \Delta \mathbf{p}} + \frac{\partial \bar{\mathbf{r}}_a}{\partial \bar{\Delta \mathbf{c}}_a} \frac{\partial \bar{\Delta \mathbf{c}}_a}{\partial \Delta \mathbf{p}}
        \\
        & = \mathbf{J}_{\mathbf{t}} - \mathbf{A}\mathbf{A}^T\mathbf{J}_{\mathbf{t}}
        \\
        & = \bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}}
    \label{eq:asymmetric_wiberg_jacobian}
    \end{aligned}
\end{equation}
The solution for $\Delta\mathbf{p}$ is obtained as usual by equating the derivative of \ref{eq:asymmetric_wiberg_problem1} with respect to $\Delta\mathbf{p}$ to 0:
\begin{equation}
    \begin{aligned}
    	\Delta \mathbf{p}^* & = - \left( \left( \bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{t}} \right)^{-1} \left( \bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^T \bar{\mathbf{r}}_a
    	\\
    	& = - \left( \mathbf{J}_{\mathbf{t}}^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{t}} \right)^{-1} \mathbf{J}_{\mathbf{t}}^T \bar{\mathbf{A}} \bar{\mathbf{r}}_a
    \label{eq:asymmetric_wiberg_solution}
    \end{aligned}
\end{equation}
where we have used:
\begin{equation}
	\begin{aligned}
		\left( \bar{\mathbf{A}}\mathbf{J}_{\mathbf{t}} \right)^T & = \mathbf{J}_{\mathbf{t}}^T \bar{\mathbf{A}}^T
		\\
		& = \mathbf{J}_{\mathbf{t}}^T \left( \mathbf{I} - \mathbf{A}\mathbf{A}^T \right)^T
		\\
		& = \mathbf{J}_{\mathbf{t}}^T \left( \mathbf{I}^T - \left( \mathbf{A}\mathbf{A}^T \right)^T \right)
		\\
		& = \mathbf{J}_{\mathbf{t}}^T \left( \mathbf{I} - \mathbf{A}\mathbf{A}^T \right)
		\\
		& = \mathbf{J}_{\mathbf{t}}^T \bar{\mathbf{A}}
	\label{eq:transposed_jacobian}
    \end{aligned}
\end{equation}
and the fact that the matrix $\bar{\mathbf{A}}$ is idempotent:
 \begin{equation}
    \begin{aligned}
    	\bar{\mathbf{A}}\bar{\mathbf{A}} & = \left( \mathbf{I} - \mathbf{A}\mathbf{A}^T \right) \left( \mathbf{I} - \mathbf{A}\mathbf{A}^T \right)
    	\\
    	& = \mathbf{I}^T\mathbf{I} - 2\mathbf{A}\mathbf{A}^T + \mathbf{A}\underbrace{\mathbf{A}^T\mathbf{A}}_{\mathbf{I}}\mathbf{A}^T
    	\\
    	& = \mathbf{I}^T\mathbf{I} - 2\mathbf{A}\mathbf{A}^T + \mathbf{A}\mathbf{A}^T
    	\\
    	& = \mathbf{I}^T\mathbf{I} - \mathbf{A}\mathbf{A}^T 
    \label{eq:idempotent_bar_A}
    \end{aligned}
\end{equation}
Therefore, the Wiberg method solves explicitly, at each iteration,  for $\Delta\mathbf{p}$ using the previous expression and implicitly for $\Delta\mathbf{c}$ (through $\bar{\Delta \mathbf{c}}_a(\Delta \mathbf{p})$) using Equation \ref{eq:asymmetric_wiberg_c_function}. The complexity per iteration of the Wiberg method is the same as the one of the Gauss-Newton method after applying the Schur complement, Equation \ref{eq:complexity_schur_asymmetric}. In fact, note that the Wiberg solution for $\Delta\mathbf{p}$ (Equation \ref{eq:asymmetric_wiberg_solution}) is the same as the one of the Gauss-Newton method after applying the Schur complement, Equation \ref{eq:asymmetric_schur_solution1}; and also note the similarity between the solutions for $\Delta\mathbf{c}$ of both methods, Equations \ref{eq:asymmetric_wiberg_c_function} and \ref{eq:asymmetric_schur_solution2}.

On the other hand, for \emph{bidirectional} composition, the residual $\bar{\mathbf{r}}_b (\Delta \mathbf{p})$ is defined as:
\begin{equation}
    \begin{aligned}
        \bar{\mathbf{r}}_b(\Delta\mathbf{q}) & = \mathbf{r}_b(\bar{\Delta \mathbf{c}}_b, \bar{\Delta \mathbf{p}}_b, \Delta\mathbf{q})
        \\
        & = \mathbf{i}[\mathbf{p} \circ \bar{\Delta \mathbf{p}}_b] - (\mathbf{a} - \mathbf{A}(\mathbf{c} + \bar{\Delta \mathbf{c}}_b))[\Delta \mathbf{q}]
    \label{eq:bidirectional_wiberg_residual}
    \end{aligned}
\end{equation}
where, similarly as before, the function $\bar{\Delta \mathbf{c}}_b(\Delta \mathbf{p}, \Delta \mathbf{q})$ is obtained solving for $\Delta \mathbf{c}$ while keeping both $\Delta \mathbf{p}$ and $\Delta \mathbf{q}$ fixed:
\begin{equation}
    \begin{aligned}
        \bar{\Delta \mathbf{c}}_b(\Delta \mathbf{p}, \Delta \mathbf{q}) & = \mathbf{A}^T \mathbf{r}_b
        \label{eq:asymmetric_wiberg_c_function}
    \end{aligned}
\end{equation}
and the function $\bar{\Delta \mathbf{p}}_b(\bar{\Delta \mathbf{c}}_b, \Delta\mathbf{q})$ is obtained by solving for $\Delta\mathbf{p}$ using the Wiberg method while keeping $\Delta \mathbf{q}$ fixed:
\begin{equation}
    \begin{aligned}
        \bar{\Delta \mathbf{p}}_b(\bar{\Delta \mathbf{c}}_b, \Delta\mathbf{q}) & = -\left( \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{i}} \right)^{-1} \mathbf{J}_{\mathbf{i}}^T \bar{\mathbf{A}} \bar{\mathbf{r}}_b
        \label{eq:asymmetric_wiberg_p_function}
    \end{aligned}
\end{equation}
At this point, the Wiberg method proceeds to define the following optimization problem with respect to $\Delta\mathbf{q}$:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{q}^* & = \underset{\Delta\mathbf{q}}{\mathrm{arg\,min\;}} \bar{\mathbf{r}}_b^T\bar{\mathbf{r}}_b
    \label{eq:bidirectional_wiberg_problem1}
    \end{aligned}
\end{equation}
which, as before, then solves approximately by performing a first order Taylor expansion around $\Delta\mathbf{q}$:
\begin{equation}
    \begin{aligned}
        \Delta\mathbf{q}^* & = \underset{\Delta\mathbf{q}}{\mathrm{arg\,min\;}}  \left\| \bar{\mathbf{r}}_b(\Delta\mathbf{q}) + \frac{\partial \bar{\mathbf{r}}_b}{\partial\Delta\mathbf{q}} \Delta\mathbf{q} \right\|^2
    \label{eq:bidirectional_wiberg_problem2}
    \end{aligned}
\end{equation}
In this case, the Jacobian of the residual can also be obtained by direct application of the chain rule and takes the following form:
\begin{equation}
    \begin{aligned}
        \frac{d \bar{\mathbf{r}}_b}{d \Delta \mathbf{q}} & = \frac{\partial \bar{\mathbf{r}}_b}{\partial \Delta \mathbf{q}} + \frac{\partial \bar{\mathbf{r}}_b}{\partial \bar{\Delta \mathbf{p}}_b} \frac{\partial \bar{\Delta \mathbf{p}}_b}{\partial \Delta \mathbf{q}} +
        \\
        & \quad \left( \frac{\partial\bar{\mathbf{r}}_b}{\partial \bar{\Delta \mathbf{c}}_b} + \frac{\partial \bar{\mathbf{r}}_b}{\partial \bar{\Delta \mathbf{p}}_b} \frac{\partial \bar{\Delta \mathbf{p}}_b}{\partial \bar{\Delta \mathbf{c}}} \right) \frac{\partial \bar{\Delta \mathbf{c}}_b}{\partial \Delta \mathbf{q}}
        \\
        & = - \mathbf{J}_{\mathbf{a}} + \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{a}} +
        \\
        & \quad \, \left(\mathbf{A} - \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{A} \right) \mathbf{A}^T \mathbf{J}_{\mathbf{a}}
        \\
        & = - \mathbf{J}_{\mathbf{a}} + \mathbf{A}\mathbf{A}^T \mathbf{J}_{\mathbf{a}} +
        \\
        & \quad \, \, \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_{\mathbf{a}} +
        \\
        & \quad - \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{A} \mathbf{A}^T \mathbf{J}_{\mathbf{a}}
        \\
        & = - \bar{\mathbf{A}} \mathbf{J}_{\mathbf{a}} +
        \\
        & \quad \, \, \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} (\mathbf{J}_{\mathbf{a}} - \mathbf{A} \mathbf{A}^T \mathbf{J}_{\mathbf{a}})
        \\
        & = - \bar{\mathbf{A}} \mathbf{J}_{\mathbf{a}} + \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \underbrace{\bar{\mathbf{A}} \bar{\mathbf{A}}}_{\bar{\mathbf{A}}} \mathbf{J}_{\mathbf{a}}
        \\
        & = \left( -\bar{\mathbf{A}} + \mathbf{J}_{\mathbf{i}} \left( \mathbf{J}_i^T \bar{\mathbf{A}} \mathbf{J}_i \right)^{-1} \mathbf{J}_i^T \bar{\mathbf{A}} \right) \mathbf{J}_{\mathbf{a}}
        \\
        & = - \mathbf{P} \mathbf{J}_{\mathbf{a}}
    \label{eq:bidirectional_wiberg_jacobian}
    \end{aligned}
\end{equation}
 And, again, the solution for $\Delta\mathbf{q}$ is obtained as usual by equating the derivative of \ref{eq:bidirectional_wiberg_problem2} with respect to $\Delta\mathbf{q}$ to 0:
 \begin{equation}
    \begin{aligned}
    	\Delta \mathbf{q}^* & = \left( \left( \mathbf{P} \mathbf{J}_{\mathbf{t}} \right)^T \mathbf{P} \mathbf{J}_{\mathbf{t}} \right)^{-1} \left( \mathbf{P} \mathbf{J}_{\mathbf{t}} \right)^T \bar{\mathbf{r}}_a
    \label{eq:bidirectional_wiberg_solution}
    \end{aligned}
\end{equation}

On the other hand, the Wiberg solutions using the project-out cost function are:
\begin{itemize}
	\item For \emph{asymmetric} composition:
	Because the project-out cost function only depends on one set of parameters, $\Delta \mathbf{p}$, in this case Wiberg reduces to Gauss-Newton.

	\item For \emph{bidirectional} composition:
	\begin{equation}
	    \begin{aligned}
	    	\bar{\Delta \mathbf{p}} & = - \left( \mathbf{J}_\mathbf{i}^T \bar{\mathbf{A}} \mathbf{J}_\mathbf{i} \right)^{-1} \mathbf{J}_\mathbf{i}^T \bar{\mathbf{i}} \mathbf{r}
	    	\\
	        \Delta \mathbf{q} & = \left( \mathbf{J}_{\bar{\mathbf{a}}}^T \mathbf{P} \mathbf{J}_{\bar{\mathbf{a}}} \right)^{-1} \mathbf{J}_{\bar{\mathbf{a}}}^T \mathbf{P} \mathbf{r}
	    \label{eq:bidirectional_wiberg_po_solution}
	    \end{aligned}
	\end{equation}
	where the bidirectional project-out Wiberg residual $\bar{\mathbf{r}}$ is defined as:
	\begin{equation}
	    \begin{aligned}
	        \bar{\mathbf{r}} = \mathbf{i}[\mathbf{p} \circ \bar{\Delta\mathbf{p}}] - \bar{\mathbf{a}}[\Delta\mathbf{q}]
	    \label{eq:po_wiberg_residual}
	    \end{aligned}
	\end{equation}
	and the optimization problem with respect to $\Delta\mathbf{q}$: 
	\begin{equation}
	    \begin{aligned}
	        \Delta\mathbf{q}^* & = \underset{\Delta\mathbf{q}}{\mathrm{arg\,min\;}} \bar{\mathbf{r}}^T\bar{\mathbf{A}}\bar{\mathbf{r}}
	    \label{eq:bidirectional_wiberg_problem1}
	    \end{aligned}
	\end{equation}
\end{itemize}
